{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skforecast.plot import set_dark_theme\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.offline as poff\n",
    "pio.templates.default = \"seaborn\"\n",
    "poff.init_notebook_mode(connected=True)\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # 'tensorflow', 'jax´ or 'torch'\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "if keras.__version__ > \"3.0\":\n",
    "    if keras.backend.backend() == \"tensorflow\":\n",
    "        import tensorflow\n",
    "    elif keras.backend.backend() == \"torch\":\n",
    "        import torch\n",
    "    else:\n",
    "        print(\"Backend not recognized. Please use 'tensorflow' or 'torch'.\")\n",
    "\n",
    "import skforecast\n",
    "from skforecast.deep_learning import ForecasterRnn\n",
    "from skforecast.deep_learning.utils import create_and_compile_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skforecast.model_selection import TimeSeriesFold\n",
    "from skforecast.model_selection import backtesting_forecaster_multiseries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    current_dir = os.getcwd()\n",
    "    ROOT_PATH = os.path.dirname(current_dir)\n",
    "    sys.path.insert(1, ROOT_PATH)\n",
    "    import root\n",
    "\n",
    "    train = pd.read_pickle(root.DIR_DATA_STAGE + 'train.pkl')\n",
    "    test = pd.read_pickle(root.DIR_DATA_STAGE + 'test.pkl')\n",
    "    return root, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(data_train, levels, lags, steps, recurrent_units, dense_units, learning_rate):\n",
    "    model = create_and_compile_model(\n",
    "        series=data_train,\n",
    "        levels=levels, \n",
    "        lags=lags,\n",
    "        steps=steps,\n",
    "        recurrent_layer=\"LSTM\",\n",
    "        recurrent_units=recurrent_units,\n",
    "        dense_units=dense_units,\n",
    "        optimizer=Adam(learning_rate=learning_rate), \n",
    "        loss=MeanSquaredError()\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forecaster(data_train, data_val, model, levels, steps, lags, epochs, batch_size):\n",
    "    forecaster = ForecasterRnn(\n",
    "        regressor=model,\n",
    "        levels=levels,\n",
    "        steps=steps,\n",
    "        lags=lags,\n",
    "        transformer_series=MinMaxScaler(),\n",
    "        fit_kwargs={\n",
    "            \"epochs\": epochs,             # Número de épocas para entrenar el modelo.\n",
    "            \"batch_size\": batch_size,     # Tamaño del batch para entrenar el modelo.\n",
    "            \"series_val\": data_val,       # Datos de validación para el entrenamiento del modelo.\n",
    "        },\n",
    "    )\n",
    "    forecaster.fit(data_train)\n",
    "    return forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtesting(data, end_val, forecaster, levels):\n",
    "    cv = TimeSeriesFold(\n",
    "        steps=forecaster.max_step,\n",
    "        initial_train_size=len(data.loc[:end_val, :]),\n",
    "        refit=False,\n",
    "    )\n",
    "    metrics, predictions = backtesting_forecaster_multiseries(\n",
    "        forecaster=forecaster,\n",
    "        series=data,\n",
    "        levels=forecaster.levels,\n",
    "        cv=cv,\n",
    "        metric=root_mean_squared_error,\n",
    "        verbose=False,\n",
    "    )\n",
    "    return metrics, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root, train, test = load_datasets()\n",
    "data = pd.concat([train, test])\n",
    "end_val = '2022-08-31 23:59:59'\n",
    "val = train.loc[end_val:]\n",
    "train = train.loc[:end_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = ['target', 'temperature', 'rain', 'snowfall', 'surface_pressure', 'cloudcover_total', 'windspeed_10m', 'winddirection_10m', 'shortwave_radiation', 'euros_per_mwh', 'installed_capacity'] \n",
    "levels = ['target']  # Serie que se quiere predecir\n",
    "steps = 24           # Pasos a futuro a predecir\n",
    "\n",
    "data_train = train[series].copy()\n",
    "data_val = val[series].copy()\n",
    "data_test = test[series].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"lags\": [24, 72],\n",
    "    \"recurrent_units\": [[100, 50], [128, 64]],\n",
    "    \"dense_units\": [[32, 16], [64, 32]],\n",
    "    \"learning_rate\": [0.01, 0.001],\n",
    "    \"epochs\": [4, 8],\n",
    "    \"batch_size\": [64, 128],\n",
    "}\n",
    "\n",
    "grid = list(product(*param_grid.values()))\n",
    "best_metrics = float(\"inf\")\n",
    "best_params = None\n",
    "best_forecaster = None\n",
    "best_predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'lags': [],\n",
    "    'recurrent_units': [],\n",
    "    'dense_units': [],\n",
    "    'learning_rate': [],\n",
    "    'epochs': [],\n",
    "    'batch_size': [],\n",
    "    'RMSE': []\n",
    "    })\n",
    "for i, params in enumerate(grid):\n",
    "    print(f\"Training model {i + 1}/{len(grid)} with params: {params}\")\n",
    "    lags, recurrent_units, dense_units, learning_rate, epochs, batch_size = params\n",
    "\n",
    "    # Create the model\n",
    "    model = create_model(data_train, levels, lags, steps, recurrent_units, dense_units, learning_rate)\n",
    "\n",
    "    # Create the forecaster\n",
    "    forecaster = create_forecaster(data_train, data_val, model, levels, steps, lags, epochs, batch_size)\n",
    "\n",
    "    # Evaluate performance using backtesting\n",
    "    metrics, predictions = backtesting(data, end_val, forecaster, levels)\n",
    "\n",
    "    # Check if this combination is the best so far\n",
    "    current_metric = metrics.root_mean_squared_error.values[0]\n",
    "    print(current_metric, type(current_metric), best_metrics, type(best_metrics))\n",
    "    if current_metric < best_metrics:\n",
    "        best_metrics = current_metric\n",
    "        best_params = params\n",
    "        best_forecaster = forecaster\n",
    "        best_predictions = predictions\n",
    "        print(f\"New best model found with RMSE: {current_metric}\")\n",
    "    \n",
    "    # Save results\n",
    "    new_row = pd.DataFrame([{\n",
    "        'recurrent_units': recurrent_units,\n",
    "        'dense_units': dense_units,\n",
    "        'learning_rate': learning_rate,\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'RMSE': current_metric\n",
    "    }])\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {best_params}\")\n",
    "print(f\"Best validation RMSE: {best_metrics}\")\n",
    "results.to_excel(root.DIR_DATA_ANALYTICS + 'LSTM_grid_search.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
